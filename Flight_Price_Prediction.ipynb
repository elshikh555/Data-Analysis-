{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWvAZNL60WNfPEie5rfZ4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elshikh555/Data-Analysis-/blob/main/Flight_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5Wyn5tDcNpBT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading training data"
      ],
      "metadata": {
        "id": "5sFkPB4OTj67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_excel('Flight Dataset/Data_Train.xlsx')\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "PpjX2ZiqN0hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking values in the Destination column"
      ],
      "metadata": {
        "id": "iOfar61mTiLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['destination'].value.counts()"
      ],
      "metadata": {
        "id": "Vt2u7TH-ODaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging Delhi and New Delhi"
      ],
      "metadata": {
        "id": "M9Kw_qE9UNue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newd(x):\n",
        "    if x=='New Delhi':\n",
        "        return 'Delhi'\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "train_data['Destination'] = train_data['Destination'].apply(newd)"
      ],
      "metadata": {
        "id": "Dgyyfg1UT6J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking info of our train data."
      ],
      "metadata": {
        "id": "tJh3EZUdU7Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "id": "jhHZW3gwU7qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Make day and month columns as Datetime columns\n",
        "\n",
        "*We will extract the journey day and journey month from the Date of the journey and make 2 columns for them as shown below.\n",
        "\n",
        "*And then we will drop the Date of the journey column."
      ],
      "metadata": {
        "id": "z2y3KOOrVe6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Journey_day'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d/%m/%Y').dt.day\n",
        "train_data['Journey_month'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d/%m/%Y').dt.month\n",
        "\n",
        "train_data.drop('Date_of_Journey',inplace=True,axis=1)\n",
        "\n",
        "train_data.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "znNmeW_JVf0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extracting hours and minutes from time.\n",
        "\n",
        "-we will extract departure hour and departure minutes from departure time.\n",
        "\n",
        "-And same will be done for arrival time.\n",
        "\n",
        "-And after that, we will drop both columns."
      ],
      "metadata": {
        "id": "XPe4bSHEW-kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Dep_hour'] = pd.to_datetime(train_data['Dep_Time']).dt.hour\n",
        "train_data['Dep_min'] = pd.to_datetime(train_data['Dep_Time']).dt.minute\n",
        "train_data.drop('Dep_Time',axis=1,inplace=True)\n",
        "\n",
        "train_data['Arrival_hour'] = pd.to_datetime(train_data['Arrival_Time']).dt.hour\n",
        "train_data['Arrival_min'] = pd.to_datetime(train_data['Arrival_Time']).dt.minute\n",
        "train_data.drop('Arrival_Time',axis=1,inplace=True)\n",
        "\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "7pBF_CiiXM3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking values in the Duration column"
      ],
      "metadata": {
        "id": "K6WOSHQuXZ5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Duration'].value_counts()"
      ],
      "metadata": {
        "id": "auH0-uscXakF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dropping the Duration column and extracting important info from it.\n",
        "- 1 We are just bringing every duration to the same format. There might be a case when some flight duration will be just 30m so we will write it as ‘0h 30m’ and there may also be cases like 2h so we will write it as ‘2h 0m’.\n",
        "- 2 Simply split it into 2 components, hour and minute.\n",
        "- 3 Add two columns ‘Duration_hours’ and ‘Duration_mins’\n",
        "- 4 Drop the original Duration column.\n"
      ],
      "metadata": {
        "id": "jXMN4pstXfTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duration = list(train_data['Duration'])\n",
        "\n",
        "for i in range(len(duration)):\n",
        "    if len(duration[i].split()) != 2:\n",
        "        if 'h' in duration[i]:\n",
        "            duration[i] = duration[i] + ' 0m'\n",
        "        else:\n",
        "            duration[i] = '0h ' + duration[i]\n",
        "\n",
        "duration_hour = []\n",
        "duration_min = []\n",
        "\n",
        "for i in duration:\n",
        "    h,m = i.split()\n",
        "    duration_hour.append(int(h[:-1]))\n",
        "    duration_min.append(int(m[:-1]))\n",
        "\n",
        "train_data['Duration_hours'] = duration_hour\n",
        "train_data['Duration_mins'] = duration_min\n",
        "\n",
        "train_data.drop('Duration',axis=1,inplace=True)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "bzaqW2FbXjIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Airline vs Price"
      ],
      "metadata": {
        "id": "XuuHybpMa2-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x='Airline',y='Price',data=train_data.sort_values('Price',ascending=False),kind='boxen',aspect=3,height=6)"
      ],
      "metadata": {
        "id": "2dsK4a5Ca3mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dummy columns out of the Airline column"
      ],
      "metadata": {
        "id": "VuhqhUKVbFt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airline = train_data[['Airline']]\n",
        "airline = pd.get_dummies(airline,drop_first=True)"
      ],
      "metadata": {
        "id": "Hr7GfCm2bGQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Source vs Price."
      ],
      "metadata": {
        "id": "6m5nvk2jbdG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If we are going from Banglore the prices are slightly higher as compared to other cities\n",
        "sns.catplot(x='Source',y='Price',data=train_data.sort_values('Price',ascending=False),kind='boxen',aspect=3,height=4)"
      ],
      "metadata": {
        "id": "_ETPdIS_bfN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dummy columns out of the Source column"
      ],
      "metadata": {
        "id": "Bpp4LlnWcEL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = train_data[['Source']]\n",
        "source = pd.get_dummies(source,drop_first=True)\n",
        "source.head()"
      ],
      "metadata": {
        "id": "kM2alJGhcEpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Destination vs Price."
      ],
      "metadata": {
        "id": "NCoYBOJOcQKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If we are going to New Delhi the prices are slightly higher as compared to other cities\n",
        "sns.catplot(x='Destination',y='Price',data=train_data.sort_values('Price',ascending=False),kind='boxen',aspect=3,height=4)"
      ],
      "metadata": {
        "id": "_Qku2Qy6cQm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dummy columns out of the Destination column"
      ],
      "metadata": {
        "id": "P7i_uhXTcgbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "destination = train_data[['Destination']]\n",
        "destination = pd.get_dummies(destination,drop_first=True)\n",
        "destination.head()"
      ],
      "metadata": {
        "id": "p6Z1YA6_ci_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping crap columns."
      ],
      "metadata": {
        "id": "gPNISpMGcrWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop(['Route','Additional_Info'],inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "6p1tott8cvi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking values in the Total stops column."
      ],
      "metadata": {
        "id": "F3i3zV3IdGjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Total_Stops'].value_counts()"
      ],
      "metadata": {
        "id": "jyvbnyrAdHcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting labels into numbers in the Total_stops column"
      ],
      "metadata": {
        "id": "pdjkDNyYdNVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# acc to the data, price is directly prop to the no. of stops\n",
        "train_data['Total_Stops'].replace({'non-stop':0,'1 stop':1,'2 stops':2,'3 stops':3,'4 stops':4},inplace=True)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "uOePGVNFdN6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the shapes of our 4 data frames"
      ],
      "metadata": {
        "id": "EeABUBJ8d3vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(airline.shape)\n",
        "print(source.shape)\n",
        "print(destination.shape)\n",
        "print(train_data.shape)"
      ],
      "metadata": {
        "id": "ZFM_ThxZd92i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine all 4 data frames."
      ],
      "metadata": {
        "id": "RUir_IAyeJPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.concat([train_data,airline,source,destination],axis=1)\n",
        "data_train.drop(['Airline','Source','Destination'],axis=1,inplace=True)\n",
        "data_train.head()"
      ],
      "metadata": {
        "id": "TMx8tCdKeKD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking out train data"
      ],
      "metadata": {
        "id": "STJY8L2Ges8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_train.drop('Price',axis=1)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "wmGE3AXyeuiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take out train data labels."
      ],
      "metadata": {
        "id": "_AvIkoa6fN5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data_train['Price']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "mjUZ2JIJfOZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking correlations between columns"
      ],
      "metadata": {
        "id": "UUrhApDgfm02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(train_data.corr(),cmap='viridis',annot=True)"
      ],
      "metadata": {
        "id": "_pRAuyC2frB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First try out the ExtraTreesRegressor model for Flight Price Prediction."
      ],
      "metadata": {
        "id": "1jMw274Df4Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = ExtraTreesRegressor()\n",
        "reg.fit(X,y)\n",
        "\n",
        "print(reg.feature_importances_)"
      ],
      "metadata": {
        "id": "IUdqtoq-f6SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking feature importance given by ExtraTreeRegressor"
      ],
      "metadata": {
        "id": "jiufGgm_gMRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,8))\n",
        "feat_importances = pd.Series(reg.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(20).plot(kind='barh')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hs9J9h0NgM9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting our data into Training and Testing data"
      ],
      "metadata": {
        "id": "87UsRY6ygpVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "9TKB8vp0gqBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Random Forest Regressor model for Flight Price Prediction.\n",
        "-Here we are using RandomizedSearchCV which just randomly tries out combinations and sees which one is the best out of them.\n",
        "\n",
        "-We have declared the parameters of RandomForestRegressor which we want to try."
      ],
      "metadata": {
        "id": "1ImCah4dg36A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 5, 10]\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}\n",
        "\n",
        "\n",
        "# Random search of parameters, using 5 fold cross validation, search across 100 different combinations\n",
        "rf_random = RandomizedSearchCV(estimator = RandomForestRegressor(), param_distributions = random_grid,\n",
        "                               scoring='neg_mean_squared_error', n_iter = 10, cv = 5,\n",
        "                               verbose=1, random_state=42, n_jobs = 1)\n",
        "rf_random.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "5LEcNOC8g4df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the best parameters we got using Randomized Search CV."
      ],
      "metadata": {
        "id": "z5FI14NVhXqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_random.best_params_"
      ],
      "metadata": {
        "id": "5a8WKFmIhYY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking Predictions"
      ],
      "metadata": {
        "id": "yvJE6Uuehdlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flight Price Prediction\n",
        "prediction = rf_random.predict(X_test)"
      ],
      "metadata": {
        "id": "jRnC54f0hiMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the residuals."
      ],
      "metadata": {
        "id": "fLJz5s9qhlvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "sns.distplot(y_test-prediction)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSlUJQNohm7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting y_test vs predictions."
      ],
      "metadata": {
        "id": "2mOHHa01h0q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "plt.scatter(y_test, prediction, alpha = 0.5)\n",
        "plt.xlabel(\"y_test\")\n",
        "plt.ylabel(\"y_pred\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QeGi1V-vh1Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing metrics."
      ],
      "metadata": {
        "id": "ia4IXRI7iCXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('r2 score: ', metrics.r2_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "7oVVfnctiC6u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}